{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# <center>Майнор \"Интеллектуальный анализ данных\"</center>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <center>Курс \"Введение в анализ данных\"</center>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <center>Лабораторная работа №3. Supervised Learning</center>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Данные"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "В рамках данной лабораторной работы вам предлагается проанализировать набор данных о студентах двух школ в Португалии.  \n",
    "В файле `students_data.csv` представлена информация о студентах, посещающих два курса - математику (`Math`) и поргутальский язык (`Por`). Некоторые студенты представлены в обоих курсах, некоторые - только в одном. Для каждого студента известны три оценки по курсу: оценка за первое полугодие (`G1`), оценка за второе полугодие (`G2`) и итоговая оценка за год (`G3`)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 40)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"students_data.csv\")\n",
    "\n",
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.head(15)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Признаки"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Данные представлены признаками различных типов: числовыми, категориальными, упорядоченными категориальными."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Описание признаков:**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.read_csv('students_data_features.csv',\n",
    "            delimiter=';',\n",
    "            encoding='windows-1251')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Часть 1. Предобработка данных"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Разделите данные на две части - данные для моделирования (80%) и отложенную выборку (20%). Убедитесь, что распределение целевой переменной (`G3`) одинаково в обоих частях.  \n",
    "  __NB__: Отложенную выборку нужно использовать только для финальной оценки качества модели. Обучение и кросс-валидацию следует проводить на данных для моделирования.  \n",
    "* Выполните необходимые преобразования данных: исправление ошибок, удаление выбросов и пропусков, приведение признаков к числовому виду.  \n",
    "* Оцените значимость признаков для определения итоговой оценки за курс. Исключите из выборки незначимые на ваш взгляд признаки, обоснуйте свое решение. \n",
    "* (Опционально) Feature engineering: создайте новые признаки (значимые) на основе уже имеющихся.\n",
    "  \n",
    "**Tip:** Используйте свои наработки из Лабораторной работы №1."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Перед разделением данных сделаем преобразование данных и исправим имеющиеся ошибки\n",
    "Выведем список всех признаков и распределим по кортжеам в 3 категории"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(data.dtypes)\n",
    "categoric = (\"Subject\", \"school\", \"sex\", \"address\",\"famsize\" ,\"Pstatus\", \"Mjob\", \"Fjob\", \"reason\", \"guardian\", \"schoolsup\", \"famsup\",\n",
    "              \"paid\", \"activities\", \"nursery\", \"higher\", \"internet\", \"romantic\", \"cheating\")\n",
    "numberic = ('ID', 'age', 'failures', 'absences', 'G1', 'G2', 'G3')\n",
    "sort_categoric = (\"Medu\", \"Fedu\", \"traveltime\", \"studytime\", \"famrel\", \"freetime\", \"goout\", \"Dalc\", \"Walc\", \"health\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Выведем уникальные значения для категориальных и упорядоченные категориальные. Найдем среди них \"плохие\" значения. Для числовых просто удостоверимся, что нет не числовых значений."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Sort Categorical Values:\")\n",
    "for value in sort_categoric:\n",
    "    print(value, data[value].unique())\n",
    "print()\n",
    "print(\"Categorical Values:\")\n",
    "for value in categoric:\n",
    "    print(value, data[value].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Теперь исправим имеющиеся ошибки"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.loc[data['Medu'] == 'o', 'Medu'] = '0'\n",
    "data.loc[data['Fedu'] == 'o', 'Fedu'] = '0'\n",
    "data.loc[data['sex'] == 'm', 'sex'] = 'M'\n",
    "data.loc[data['Pstatus'] == 't', 'Pstatus'] = 'T'\n",
    "data.loc[data['Mjob'] == 'at-home', 'Mjob'] = 'at_home'\n",
    "data.loc[data['Fjob'] == 'at-home', 'Fjob'] = 'at_home'\n",
    "data.loc[data['guardian'] == 'futher', 'guardian'] = 'father'\n",
    "\n",
    "print(\"Sort Categorical Values:\")\n",
    "for value in sort_categoric:\n",
    "    print(value, data[value].unique())\n",
    "print()\n",
    "print(\"Categorical Values:\")\n",
    "for value in categoric:\n",
    "    print(value, data[value].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Также исправим типы некоторых значений"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "data[['Medu', 'Fedu']] = data[['Medu', 'Fedu']].astype(np.int64)\n",
    "print(data.dtypes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Исправим проблему с пустыми ячейками, удалив столбцы с большим количеством пропущенных значений, а некоторые заменив на среднее значение"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(data.isnull().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "columns = data.columns.values.tolist()\n",
    "empty_columns = list()\n",
    "for value in columns:\n",
    "    if data[value].isnull().sum() != 0:\n",
    "        if(data[value].dtypes == 'object'):    \n",
    "            data = data.fillna({value : data[value].value_counts().index[0]})\n",
    "        else:\n",
    "            data = data.fillna({value : data[value].median()})\n",
    "data.drop(columns=[\"cheating\"], inplace=True)\n",
    "print(data.isnull().sum())\n",
    "print(data.dtypes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['Walc'] = data['Walc'].apply(int, convert_dtype=True)\n",
    "data['Dalc'] = data['Dalc'].apply(int, convert_dtype=True)\n",
    "data['famrel'] = data['famrel'].apply(int, convert_dtype=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Выполним кодирование для категориальных переменных (Label Encoding)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def countable(df=data):\n",
    "    all_categories = list(categoric)\n",
    "    all_categories.remove(\"cheating\")\n",
    "    all_categories_dict = dict()\n",
    "    for value in all_categories:\n",
    "        all_categories_dict[value] = set(data[value].unique())\n",
    "    for i in all_categories_dict:\n",
    "        all_categories_dict[i] = (all_categories_dict[i], len(all_categories_dict[i]))\n",
    "    return all_categories_dict\n",
    "\n",
    "data_enc_label = data[[column for column in data.columns if data[column].dtypes == 'object']].copy()\n",
    "categ = [column for column in data.columns if data[column].dtypes == 'object']\n",
    "labelencoder = LabelEncoder()\n",
    "for i in categ:\n",
    "    data_enc_label[i] = labelencoder.fit_transform(data_enc_label[i])\n",
    "data_enc_label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Теперь выполним One Hot Encoding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_enc_label.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "hot = OneHotEncoder(handle_unknown='ignore')\n",
    "categories_data = countable(data[[column for column in data.columns if data[column].dtypes == 'object']].copy())\n",
    "one_hot_df = pd.DataFrame(hot.fit_transform(data_enc_label[['Mjob', 'Fjob', 'guardian', 'reason']]).toarray())\n",
    "one_hot_df.columns = [column + '_'+ str(list(categories_data[column][0])[i]) for column in ['Mjob', 'Fjob', 'guardian', 'reason']\n",
    "                      for i in range(categories_data[column][1])]\n",
    "for column in one_hot_df.columns:\n",
    "     one_hot_df[column] = one_hot_df[column].apply(int, convert_dtype=True)\n",
    "        \n",
    "data_enc_label = data_enc_label.drop(['Mjob', 'Fjob', 'guardian', 'reason'], axis=1)\n",
    "data_enc_label.columns = [column + '_'+ str(list(categories_data[column][0])[1]) for column in data_enc_label.columns]\n",
    "data_object_encoded = data_enc_label.join(one_hot_df)\n",
    "encoded_df = data_enc_label.join(one_hot_df)\n",
    "encoded_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = data['G3']\n",
    "objects = [label for label in data.columns if data[label].dtypes == 'object']\n",
    "l_data = data.drop(columns=['ID','G3'])\n",
    "l_data = l_data.drop(columns=objects)\n",
    "l_data = l_data.join(data_object_encoded)\n",
    "l_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "l_data_out_G1 = l_data.drop(columns=['G1'])\n",
    "l_data_out_G1.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature engineerign \n",
    "Рассмотрим коррреляцию признаков"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50, 50))\n",
    "sns.heatmap(l_data.corr(), annot=True, fmt=\".2f\", linewidths=.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Признаки с высокой корреляцией\n",
    "Medu и Fedu\n",
    "Walc и Dalc\n",
    "При этом можно их можно выразить путем объединения\n",
    "То есть общее отношение к алкоголю и образование родителей"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "l_data['Сalc'] = l_data.loc[:, ['Walc', 'Dalc']].sum(1)\n",
    "l_data['Pedu'] = l_data.loc[:, ['Fedu', 'Medu']].sum(1)\n",
    "l_data = l_data.drop(columns=['Walc', 'Dalc', 'Fedu', 'Medu'])\n",
    "l_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "l_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = labels\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(l_data, y, test_size=0.2)\n",
    "#x_out_g1_train, x_out_g1_test, y_train, y_test = train_test_split(x_out_g1, y, test_size=0.2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = sns.kdeplot(y_train, shade=True, color=\"b\")\n",
    "fig = sns.kdeplot(y_test, shade=True, color=\"r\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Распределение G3 одинаково"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Также сделаем стандартизацию данных"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# scal = StandardScaler()\n",
    "# x_train = scal.fit_transform(x_train)\n",
    "# x_test = scal.transform(x_test)\n",
    "# x_out_g1_train = scal.fit_transform(x_out_g1_train)\n",
    "# x_out_g1_test = scal.transform(x_out_g1_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Часть 2. Регрессия"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Решите задачу регрессии: постройте модель, предсказывающую итоговую оценку, которую получит студент по предмету (`G3`). При решении задачи **нельзя** использовать признак `G2`.  \n",
    "<br>  \n",
    "* Для решения задачи примените следующие методы:  \n",
    "  * Линейная регрессия + регуляризации  \n",
    "  * Полиномиальная регрессия  \n",
    "  * KNN  \n",
    "  * Деревья решений, Random Forest  \n",
    "  \n",
    "  Для каждого метода выполните настройку гиперпараметров на кросс-валидации.  \n",
    "<br>    \n",
    "* Оцените качество каждой модели на отложенной выборке, используйте различные метрики. Сравните модели и сделайте вывод о качестве решения задачи.  \n",
    "<br>    \n",
    "* Задачу необходимо решить в двух вариантах: с использованием признака `G1`  и без него. Сравните качество решений в двух случаях.  \n",
    "<br>    \n",
    "* В регрессионных моделях попробуйте дать интерпретацию весам признаков. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, LassoCV, RidgeCV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def print_metrics(current, prediction):\n",
    "    print(\"MSE \", metrics.mean_squared_error(current, prediction))\n",
    "    print(\"RMSE \", np.sqrt(metrics.mean_squared_error(current, prediction)))\n",
    "    print(\"R2 \", metrics.r2_score(current, prediction))\n",
    "    print(\"MAE \", metrics.mean_absolute_error(current, prediction))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test\n",
    "x_train_out_G2 = x_train.drop(\"G2\", axis=1)\n",
    "x_test_out_G2 = x_test.drop(\"G2\", axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### With G1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Linear Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(x_train_out_G2, y_train)\n",
    "y_pred = lin_reg.predict(x_test_out_G2)\n",
    "print(\"Linear Regression:\")\n",
    "print_metrics(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ridge Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lambdas = [0, 0.1, 0.5, 1, 5, 10, 25, 50, 100, 250, 500, 1000, 5000, 10000]\n",
    "ridgecv = RidgeCV(alphas=lambdas, cv=5)\n",
    "ridgecv.fit(x_train_out_G2, y_train)\n",
    "y_pred = ridgecv.predict(x_test_out_G2)\n",
    "print(\"Ridge regression\")\n",
    "print_metrics(y_test, y_pred)\n",
    "print(\"The best Ridge: \", ridgecv.alpha_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(ridgecv.coef_))\n",
    "print(len(x_train_out_G2.columns))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Судя по весам предсказание делается из studytime, G1 "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Lasso Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lasso = LassoCV(alphas=np.arange(0.1, 10, 0.1), normalize=True, cv=5)\n",
    "lasso.fit(x_train_out_G2, y_train)\n",
    "y_pred = lasso.predict(x_test_out_G2)\n",
    "print(\"Lasso regression\")\n",
    "print_metrics(y_test, y_pred)\n",
    "print(f\"The best Lasso : \", lasso.alpha_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Without C1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train_out_G2_G1 = x_train_out_G2.drop('G1', axis=1)\n",
    "x_test_out_G2_G1 = x_test_out_G2.drop('G1', axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Linear Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(x_train_out_G2_G1, y_train)\n",
    "y_pred = lin_reg.predict(x_test_out_G2_G1)\n",
    "print(\"Linear Regression:\")\n",
    "print_metrics(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Lasso Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lasso = LassoCV(alphas=np.arange(0.1, 10, 0.1), normalize=True, cv=5)\n",
    "lasso.fit(x_train_out_G2_G1, y_train)\n",
    "y_pred = lasso.predict(x_test_out_G2_G1)\n",
    "print(\"Lasso regression\")\n",
    "print_metrics(y_test, y_pred)\n",
    "print(f\"The best Lasso : \", lasso.alpha_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(lasso.coef_)\n",
    "print(len(x_test_out_G2_G1.columns))\n",
    "#print_weights(lasso, x_test_out_G2_G1.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ridge Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lambdas = [0, 0.1, 0.5, 1, 5, 10, 25, 50, 100, 250, 500, 1000, 5000, 10000]\n",
    "ridgecv = RidgeCV(alphas=lambdas, cv=5)\n",
    "ridgecv.fit(x_train_out_G2_G1, y_train)\n",
    "y_pred = ridgecv.predict(x_test_out_G2_G1)\n",
    "print(\"Ridge regression\")\n",
    "print_metrics(y_test, y_pred)\n",
    "print(\"The best Ridge: \", ridgecv.alpha_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Polynomial Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### With G1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "degrees = [2, 3, 4]\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import linear_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in degrees:\n",
    "    pol = PolynomialFeatures(degree=i, include_bias=False)\n",
    "    pol.fit(x_train_out_G2)\n",
    "    pol_train = pol.transform(x_train_out_G2)\n",
    "    pol_test = pol.transform(x_test_out_G2)\n",
    "    pol_reg_model = linear_model.LinearRegression(normalize=True)\n",
    "    pol_reg_model.fit(pol_train, y_train)\n",
    "    y_pred = pol_reg_model.predict(pol_test)\n",
    "    print(\"Degree \", i)\n",
    "    print_metrics(y_test, y_pred)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Without G1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in degrees:\n",
    "    pol = PolynomialFeatures(degree=i, include_bias=False)\n",
    "    pol.fit(x_train_out_G2_G1)\n",
    "    pol_train = pol.transform(x_train_out_G2_G1)\n",
    "    pol_test = pol.transform(x_test_out_G2_G1)\n",
    "    pol_reg_model = linear_model.LinearRegression(normalize=True)\n",
    "    pol_reg_model.fit(pol_train, y_train)\n",
    "    y_pred = pol_reg_model.predict(pol_test)\n",
    "    print(\"Degree \", i)\n",
    "    print_metrics(y_test, y_pred)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### KNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### With G1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "parametrs = {'n_neighbors': range(1, 70), \n",
    "             'weights':['distance', 'uniform']}\n",
    "grid = GridSearchCV()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Часть 3. Бинарная классификация"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Решите задачу бинарной классификации: постройте модель, предсказывающую, сдаст студент предмет (`G3` >= 8) или не сдаст (`G3` < 8). <br>При решении задачи **нельзя** использовать признаки `G1` и `G2`.  \n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Задание 1  \n",
    "  \n",
    "* Постройте дерево решений глубины 5 (остальные параметры по умолчанию), оцените качество на 5-fold валидации.  \n",
    "* Для одного из деревьев (т.е. обученного на одной из итераций кросс-валидации) выведите само дерево - постройте график или выведите в текстовом виде. По структуре дерева сформулируйте правила, по которым принимается решение.  \n",
    "* Сравните между собой деревья решений, полученных на различных итерациях 5-fold валидации. Сделайте вывод, насколько сильно они похожи или различаются между собой. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# your code here"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Задание 2  \n",
    "  \n",
    "На кросс-валидации (5-fold из 2 повторений) оцените, как меняется качество модели Random Forest с ростом числа деревьев (при дефолтных значениях остальных параметров). Провизуализируйте результаты. Сколько деревьев достаточно в данном случае и почему?  \n",
    "**NB:** В сравнение включите конфигурацию, аналогичную простому дереву решений. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# your code here"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Задание 3  \n",
    "  \n",
    "* Настройте гиперпараметры модели Random Forest на 5-fold валдиации. В качестве метрики используйте F1-score. Замерьте время, затраченное на вычисления.\n",
    "* Обучите Random Forest  с настроенными параметрами на всех данных для моделирования. На отложенной выборке оцените качество (F1-score) всего ансамбля и <u>каждого дерева отдельно</u>. Постройте график распределения качества деревьев в ансамбле и сравните результаты с качеством всего леса. Дайте комментарий.  \n",
    "* Выведите важность признаков в Random Forest, сделайте выводы. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# your code here"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Задание 4  \n",
    "  \n",
    "* Примените логистическую регрессию для решения задачи, подберите оптимальные значения гиперпараметров. Оцените качество (roc auc) на 5-fold валидации из 2 повторений. \n",
    "* Аналогично (на такой же валидации (тех же подвыборках) с такой же метрикой) оцените качество Random Forest  с подобранными в предыдущем задании параметрами. Сравните с качеством логистическом регрессии.\n",
    "* Обучите логистическую модель с настроенными параметрами на всех данных для моделирования. На отложенной выборке оцените качество - постройте ROC-кривую, вычислите roc auc. Вычислите аналогичную метрику для Random Forest из Задания 3, сравните точность моделей. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# your code here"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Задание 5  \n",
    "  \n",
    "* Используйте для решения задачи один из фреймворков градиентного бустинга: XGBoost, LightGDB или CatBoost.  \n",
    "* Оцените на 5-fold валидации, как растет качество модели на обучающей и на тестовой выборках при добавлении каждого дерева. Провизуализируйте результаты.  \n",
    "* Настройте гиперпараметры модели на 5-fold валидации, в качестве метрики используйте F1-score. Замерьте время, затраченное на вычисления.  \n",
    "* Обучите модель с настроенными параметрами на всех данных для моделирования и оцените качество на отложенной выборке. Сравните результаты с другими моделями, дайте комментарий."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# your code here"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##  Часть 4. Многоклассовая классификация\n",
    "  \n",
    "* Решите задачу многоклассовой классификации: постройте модель, пресдказывающую оценку студента по предмету по 4 балльной шкале\n",
    "    - Отлично: 18 <= `G3` <= 20\n",
    "    - Хорошо: 14 <= `G3` <= 17\n",
    "    - Удовлетворительно: 8 <= `G3` <= 13\n",
    "    - Неудовлетворительно: `G3` < 8  \n",
    "  \n",
    "  При решении задачи **нельзя** использовать признаки `G1` и `G2`.  \n",
    "  \n",
    "  \n",
    "* Для решения задачи примените следующие методы:  \n",
    "  * KNN  \n",
    "  * Логистическая регрессия  \n",
    "  * Деревья решений  \n",
    "  * Random Forest\n",
    "  * Gradient Boosting\n",
    "  \n",
    "  На кросс-валидации подберите оптимальные значения гиперпараметров алгоритмов.  \n",
    "  \n",
    "  \n",
    "* Оцените качество моделей, используйте confusion matrix и производные от нее метрики. Сделайте выводы.    "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# your code here"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}